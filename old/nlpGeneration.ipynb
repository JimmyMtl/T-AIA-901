{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "from spacy import displacy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Chargez le modèle français de Spacy\n",
    "nlp = spacy.blank(\"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Créer un pipeline NER\n",
    "ner = nlp.add_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner.add_label(\"DEP\")\n",
    "ner.add_label(\"ARR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1812 453\n"
     ]
    }
   ],
   "source": [
    "DATA = []\n",
    "\n",
    "with open('inputs.txt', mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    contents = f.readlines()\n",
    "    for line in contents:\n",
    "        DATA.append(eval(line))\n",
    "\n",
    "# Vous pouvez séparer ces données en deux ensembles de la manière suivante :\n",
    "X = [text for text, annotations in DATA]\n",
    "y = [annotations['entities'] for text, annotations in DATA]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'U-ARR', 'O', 'U-DEP', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Vérifier les offsets des entités dans le jeu de données d'entraînement ajusté\n",
    "doc = nlp.make_doc(X_train[0])\n",
    "bilou_tags = spacy.training.offsets_to_biluo_tags(doc, y_train[0])\n",
    "print(bilou_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<thinc.optimizers.Optimizer at 0x1379cf180>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Débuter l'entraînement\n",
    "nlp.begin_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 362.9715826177771}\n",
      "{'ner': 95.22898860958165}\n",
      "{'ner': 106.49668624028948}\n",
      "{'ner': 9.090611384918336}\n",
      "{'ner': 77.51224101806304}\n"
     ]
    }
   ],
   "source": [
    "from spacy.training.example import Example\n",
    "\n",
    "# Train\n",
    "histo_loss = []\n",
    "for itn in range(10):\n",
    "    losses = {}\n",
    "    for i in range(len(X_train)):\n",
    "        # create Example\n",
    "        doc = nlp.make_doc(X_train[i])\n",
    "        example = Example.from_dict(doc, {\"entities\": y_train[i]})\n",
    "        # Update the model\n",
    "        nlp.update([example], losses=losses, drop=0.2)\n",
    "    histo_loss.append(losses['ner'])\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# draw loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(histo_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(nlp.get_pipe(\"ner\").labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Utiliser le modèle pour détecter des entités\n",
    "doc = nlp(\"Demain il faut que je me rende a Paris depuis Marseille\")\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "doc = nlp(\"I need to go to Paris from Marseille tomorrow\")\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# export model\n",
    "nlp.to_disk(\"model_ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dep_true = []\n",
    "dep_pred = []\n",
    "arr_true = []\n",
    "arr_pred = []\n",
    "\n",
    "# predict the test data\n",
    "for i in range(len(X_test)):\n",
    "    doc = nlp(X_test[i])\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'DEP':\n",
    "            dep_pred.append(ent.text)\n",
    "        if ent.label_ == 'ARR':\n",
    "            arr_pred.append(ent.text)\n",
    "\n",
    "    arr_true.append(X_test[i][y_test[i][0][0]:y_test[i][0][1]])\n",
    "    dep_true.append(X_test[i][y_test[i][1][0]:y_test[i][1][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#accuracy of DEP\n",
    "print('dep accuracy', accuracy_score(dep_true, dep_pred)*100, '%')\n",
    "\n",
    "#accuracy of ARR\n",
    "print('arr accuracy', accuracy_score(arr_true, arr_pred)*100, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7003674ed90aa0b1bf19fd6f6cf3343126870b92d3009df07a75c6902a221258"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}